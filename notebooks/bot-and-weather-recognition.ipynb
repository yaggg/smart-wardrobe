{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "bot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "pycharm-868f94c6",
   "language": "python",
   "display_name": "PyCharm (ai-preparement)"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "6eEgNSvLYKAE",
    "colab_type": "code",
    "outputId": "6891f053-4ff0-4e85-a016-d1c8724d9b51",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "!pip install python-telegram-bot --upgrade"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Collecting python-telegram-bot\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/8f/e1ae8acee0398c041464ceb97be4f76819876df8585660ee402e92015d44/python_telegram_bot-12.3.0-py2.py3-none-any.whl (351kB)\r\n",
      "\u001b[K     |████████████████████████████████| 358kB 709kB/s eta 0:00:01\r\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: future>=0.16.0 in /home/yakov/anaconda3/lib/python3.7/site-packages (from python-telegram-bot) (0.18.2)\r\n",
      "Requirement already satisfied, skipping upgrade: certifi in /home/yakov/anaconda3/lib/python3.7/site-packages (from python-telegram-bot) (2019.11.28)\r\n",
      "Requirement already satisfied, skipping upgrade: tornado>=5.1 in /home/yakov/anaconda3/lib/python3.7/site-packages (from python-telegram-bot) (6.0.3)\r\n",
      "Requirement already satisfied, skipping upgrade: cryptography in /home/yakov/anaconda3/lib/python3.7/site-packages (from python-telegram-bot) (2.8)\r\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /home/yakov/anaconda3/lib/python3.7/site-packages (from cryptography->python-telegram-bot) (1.13.2)\r\n",
      "Requirement already satisfied, skipping upgrade: six>=1.4.1 in /home/yakov/anaconda3/lib/python3.7/site-packages (from cryptography->python-telegram-bot) (1.13.0)\r\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /home/yakov/anaconda3/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography->python-telegram-bot) (2.19)\r\n",
      "Installing collected packages: python-telegram-bot\r\n",
      "Successfully installed python-telegram-bot-12.3.0\r\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "naKuAnOTcyi2",
    "colab_type": "code",
    "outputId": "e8119ec0-250c-405f-e1c3-7f3bda955fe3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    }
   },
   "source": [
    "#colab не может работать с версиями новее\n",
    "!pip uninstall tornado\n",
    "!pip install tornado==4.5.3"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Uninstalling tornado-6.0.3:\n",
      "  Would remove:\n",
      "    /usr/local/lib/python3.6/dist-packages/tornado-6.0.3.dist-info/*\n",
      "    /usr/local/lib/python3.6/dist-packages/tornado/*\n",
      "Proceed (y/n)? y\n",
      "  Successfully uninstalled tornado-6.0.3\n",
      "Collecting tornado==4.5.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/7b/e29ab3d51c8df66922fea216e2bddfcb6430fb29620e5165b16a216e0d3c/tornado-4.5.3.tar.gz (484kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 3.4MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: tornado\n",
      "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tornado: filename=tornado-4.5.3-cp36-cp36m-linux_x86_64.whl size=433070 sha256=51037c785d4516a69ed504615507691e2acc7a56728eb4d2621f938a38c95a77\n",
      "  Stored in directory: /root/.cache/pip/wheels/72/bf/f4/b68fa69596986881b397b18ff2b9af5f8181233aadcc9f76fd\n",
      "Successfully built tornado\n",
      "\u001b[31mERROR: python-telegram-bot 12.3.0 has requirement tornado>=5.1, but you'll have tornado 4.5.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tornado\n",
      "Successfully installed tornado-4.5.3\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "tornado"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mojwz_hnYNwg",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import logging\n",
    "import telegram\n",
    "from telegram.error import NetworkError, Unauthorized\n",
    "from time import sleep\n",
    "\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dlGk76Y_93xD",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from torchvision import transforms\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from matplotlib import colors, pyplot as plt\n",
    "%matplotlib inline"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rqGv1GJ41TaQ",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# разные режимы датасета \n",
    "DATA_MODES = ['train', 'val', 'test']\n",
    "# все изображения будут масштабированы к размеру 224x224 px\n",
    "RESCALE_SIZE = 224\n",
    "# работаем на видеокарте\n",
    "DEVICE = torch.device(\"cpu\")"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VCsqrshmwY8I",
    "colab_type": "code",
    "outputId": "a3a16b69-732a-4131-9a94-8366464ef24d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "#model init\n",
    "model_ft = torch.load('../models/m81.pth', map_location={'cuda:0': 'cpu'})\n",
    "model_ft.eval()\n"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=6, bias=True)\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o10KS--Lsd-q",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def predict_one_sample(model, inputs, device=DEVICE):\n",
    "    \"\"\"Предсказание, для одной картинки\"\"\"\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.to(device)\n",
    "        model.eval()\n",
    "        logit = model(inputs).cpu()\n",
    "        print(logit.shape)\n",
    "        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n",
    "    return probs"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9UTbU0Zbc6Hb",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def get_weather(model, image):\n",
    "  transform = transforms.Compose([\n",
    "              transforms.Resize((RESCALE_SIZE, RESCALE_SIZE)),\n",
    "              transforms.ToTensor(),\n",
    "              transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "          ])\n",
    "  image = transform(image)\n",
    "  pred = predict_one_sample(model, image.unsqueeze(0))\n",
    "  label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
    "  preds = label_encoder.inverse_transform(np.argmax(pred, axis=1))\n",
    "  return preds"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YuAwY-Q_9iG9",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def load_sample(file):\n",
    "        image = Image.open(file).convert('RGB')\n",
    "        image.load()\n",
    "        return image"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QL8l7-nCYs_Y",
    "colab_type": "code",
    "outputId": "ae48a9a2-b2aa-407d-d5b5-d770828a623a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def get_help(bot, update):\n",
    "    update.message.reply_text(\"Send photo to get clothes recommendation\")\n",
    "\n",
    "def image_handler(bot, update):\n",
    "    global model_ft\n",
    "    print(update.message)\n",
    "    img_path = \"image1.jpg\"\n",
    "    img_id = update.message.photo[-1].file_id\n",
    "    print(img_id)\n",
    "    img = bot.get_file(img_id)\n",
    "    img.download(img_path)\n",
    "    img = load_sample(img_path)\n",
    "    weather = get_weather(model_ft, img)\n",
    "    print(weather)\n",
    "    update.message.reply_text(weather[0])\n",
    "\n",
    "def main():\n",
    "    # Create the Updater and pass it your bot's token.\n",
    "    # Make sure to set use_context=True to use the new context based callbacks\n",
    "    # Post version 12 this will no longer be necessary\n",
    "    updater = Updater(\"1056944645:AAELDA_hclG4RV402WNw89IE9TLt25F_OIM\")\n",
    "\n",
    "    # Get the dispatcher to register handlers\n",
    "    dp = updater.dispatcher\n",
    "\n",
    "    # simple start function\n",
    "    dp.add_handler(MessageHandler(Filters.photo, image_handler))\n",
    "    dp.add_handler(CommandHandler(\"help\", get_help))\n",
    "\n",
    "    # Start the Bot\n",
    "    updater.start_polling()\n",
    "\n",
    "    # Run the bot until you press Ctrl-C or the process receives SIGINT,\n",
    "    # SIGTERM or SIGABRT. This should be used most of the time, since\n",
    "    # start_polling() is non-blocking and will stop the bot gracefully.\n",
    "    updater.idle()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: TelegramDeprecationWarning: Old Handler API is deprecated - see https://git.io/fxJuV for details\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "{'message_id': 30, 'date': 1581001036, 'chat': {'id': 846020196, 'type': 'private', 'username': 'dmitriy_vahrushev', 'first_name': 'Dmitriy', 'last_name': 'Vahrushev'}, 'entities': [], 'caption_entities': [], 'photo': [{'file_id': 'AgACAgIAAxkBAAMeXjwpTP91f1rT8KKcgD6tgn9iCtcAAuKtMRswvuFJlfJ8It2a64kKd8EPAAQBAAMCAANtAANxHgQAARgE', 'width': 240, 'height': 320, 'file_size': 16349}, {'file_id': 'AgACAgIAAxkBAAMeXjwpTP91f1rT8KKcgD6tgn9iCtcAAuKtMRswvuFJlfJ8It2a64kKd8EPAAQBAAMCAAN4AANyHgQAARgE', 'width': 599, 'height': 800, 'file_size': 81730}, {'file_id': 'AgACAgIAAxkBAAMeXjwpTP91f1rT8KKcgD6tgn9iCtcAAuKtMRswvuFJlfJ8It2a64kKd8EPAAQBAAMCAAN5AANzHgQAARgE', 'width': 956, 'height': 1276, 'file_size': 189971}], 'new_chat_members': [], 'new_chat_photo': [], 'delete_chat_photo': False, 'group_chat_created': False, 'supergroup_chat_created': False, 'channel_chat_created': False, 'from': {'id': 846020196, 'first_name': 'Dmitriy', 'is_bot': False, 'last_name': 'Vahrushev', 'username': 'dmitriy_vahrushev', 'language_code': 'en'}}\n",
      "AgACAgIAAxkBAAMeXjwpTP91f1rT8KKcgD6tgn9iCtcAAuKtMRswvuFJlfJ8It2a64kKd8EPAAQBAAMCAAN5AANzHgQAARgE\n",
      "torch.Size([1, 6])\n",
      "['sunny']\n",
      "{'message_id': 32, 'date': 1581001113, 'chat': {'id': 846020196, 'type': 'private', 'username': 'dmitriy_vahrushev', 'first_name': 'Dmitriy', 'last_name': 'Vahrushev'}, 'entities': [], 'caption_entities': [], 'photo': [{'file_id': 'AgACAgIAAxkBAAMgXjwpmQ4uIaA9LNyTCuLTPQfQAAEMAALprTEbML7hSbD4HS3oIU9FkgXBDgAEAQADAgADbQADWIsCAAEYBA', 'width': 320, 'height': 240, 'file_size': 21799}, {'file_id': 'AgACAgIAAxkBAAMgXjwpmQ4uIaA9LNyTCuLTPQfQAAEMAALprTEbML7hSbD4HS3oIU9FkgXBDgAEAQADAgADeAADWYsCAAEYBA', 'width': 800, 'height': 600, 'file_size': 115007}, {'file_id': 'AgACAgIAAxkBAAMgXjwpmQ4uIaA9LNyTCuLTPQfQAAEMAALprTEbML7hSbD4HS3oIU9FkgXBDgAEAQADAgADeQADVosCAAEYBA', 'width': 854, 'height': 640, 'file_size': 128620}], 'new_chat_members': [], 'new_chat_photo': [], 'delete_chat_photo': False, 'group_chat_created': False, 'supergroup_chat_created': False, 'channel_chat_created': False, 'from': {'id': 846020196, 'first_name': 'Dmitriy', 'is_bot': False, 'last_name': 'Vahrushev', 'username': 'dmitriy_vahrushev', 'language_code': 'en'}}\n",
      "AgACAgIAAxkBAAMgXjwpmQ4uIaA9LNyTCuLTPQfQAAEMAALprTEbML7hSbD4HS3oIU9FkgXBDgAEAQADAgADeQADVosCAAEYBA\n",
      "torch.Size([1, 6])\n",
      "['snow']\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}